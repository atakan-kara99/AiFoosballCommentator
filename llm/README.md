# LLM Commentary System

This module provides real-time natural language commentary generation for foosball events using Large Language Models (LLM). The system processes game events, generates contextual prompts, and delivers natural-sounding commentary with support for interrupts and statistical insights.

## ğŸ“ Directory Structure

```
llm/
â”œâ”€â”€ modules/                          # Core functionality modules
â”‚   â”œâ”€â”€ buffer.py                      # Event buffering and prioritization
â”‚   â”œâ”€â”€ commentator.py                 # Natural speech output management
â”‚   â”œâ”€â”€ event_cleaner.py               # Event data validation and processing
â”‚   â”œâ”€â”€ llm_interface.py               # LLM model interaction
â”‚   â””â”€â”€ prompt_generator.py            # Context-aware prompt generation
â”œâ”€â”€ tests/                            # Test suites
â”‚   â”œâ”€â”€ resources/                     # Test data
â”‚   â”œâ”€â”€ test_buffer.py                 # Buffer component tests
â”‚   â”œâ”€â”€ test_llm_interface.py          # LLM interface tests
â”‚   â”œâ”€â”€ test_pipeline.py               # Multi-threaded pipeline tests
â”‚   â”œâ”€â”€ test_pipeline_presentation.py  # Presentation pipeline tests
â”‚   â””â”€â”€ test_prompt_generator.py       # Prompt generation tests
â”œâ”€â”€ config.py                         # System configuration
â””â”€â”€ llm.py                            # Main module entry point
```

## ğŸ”§ Components

### Core Modules

1. **Buffer (`modules/buffer.py`)**
   - Priority-based event queueing
   - Overflow management
   - Interest score calculation

2. **Commentator (`modules/commentator.py`)**
   - Natural speech delivery
   - Interrupt handling
   - Speech pacing control

3. **Event Cleaner (`modules/event_cleaner.py`)**
   - Event data validation
   - Priority assignment
   - Interrupt detection

4. **LLM Interface (`modules/llm_interface.py`)**
   - Model initialization and management
   - Text generation
   - Error handling

5. **Prompt Generator (`modules/prompt_generator.py`)**
   - Context-aware prompt creation
   - Template management
   - Event type matching

## ğŸš€ Features

- Real-time event processing
- Natural language commentary
- Priority-based event handling
- Interrupt support for critical events
- Statistical insights generation
- Multi-threaded pipeline architecture

## ğŸ§ª Testing

The `tests/` directory contains test suites for each component:

- Unit tests for individual modules
- Integration tests for the pipeline
- Performance tests for real-time processing
- Presentation-ready pipeline tests

## âš™ï¸ Configuration

System settings are managed through `config.py`, including:
- LLM model parameters
- Template configurations
- Buffer settings
- Speech parameters

## ğŸ”‘ Requirements

- Python 3.12.9
- HuggingFace Transformers
- Environment variable: `HUGGINGFACE_TOKEN` for model access

## ğŸš¦ Pipeline Architecture

The system follows a producer-consumer architecture:
1. Event Producer: Processes and validates game events
2. Buffer: Manages event priority and queueing
3. Commentary Generator: Creates contextual prompts
4. Speech Output: Delivers natural commentary

## ğŸ” Usage Example

```python
from llm.modules import llm_interface, commentator

# Initialize components
llm = llm_interface.LLMInterface(model="meta-llama/Llama-3.2-3B-Instruct")
speaker = commentator.Commentator()

# Process event and generate commentary
event = {"event": "goal", "team": "Team A", "player": "Player 1"}
comment = llm.generate_comment(event)
speaker.speak(comment)
```

## ğŸ”— Related Components

- `cv/` - Computer vision for event detection
- `markov/` - Statistical modeling
- `visual/` - Visualization components